\section[Des CSU pour les CIOE de Stupfel et Poget 2011]{Des conditions suffisante pour les CIOE de \cite{stupfel_sufficient_2011}}

  Nous définissons les \glspl{acr-cioe} comme une condition limite liant \(\vE_t\) et \(\vn\pvect\vH\) sur \(\Gamma\). L'existence des CIOE est en dehors du cadre de cette thèse, nous ne ferons donc qu'utiliser des CIOE existantes.

  Grâce à ces CIOE, nous allons établir des conditions suffisante qui impliquent la \gls{acr-cgu} \eqref{eq:unicite:form_var:cgu}. Par leur nature suffisante, il n'y pas un unique jeu de CSU pour une CIOE donnée. Une difficulté est d'être capable de juger si ce jeu est satisfaisant, et si ce n'est pas le cas, être capable de proposer un autre jeu.

  Les CIOE de \cite{stupfel_sufficient_2011} font intervenir l'opérateur de Hodge \(\mathcal{L}\), commençons par rappeler son expression et quelques propriétés.

  \begin{defn}
    % Pour tout \(\vu \in (\mathcal{C}^\infty(\Gamma))^2\)
    \begin{equation}
      \label{eq:operator:L}
        \fonction{\LL}{(\mathcal{C}^\infty(\Gamma))^2}{(\mathcal{C}^\infty(\Gamma))^2}%
          {\vu}{\tgrads{\tdivs \vu} - \tvrots{\tvrots \vu}}
    \end{equation}
  \end{defn}

  \begin{prop}
    Par définition, l’opérateur hermitien \(\LL\) est symétrique négatif.

    Pour tous \(\vu,\vv \in (\mathcal C^\infty(\Gamma))^2\)
    \begin{align}
      \int_\Gamma \vu\cdot \LL(\conj{\vv}) &= \int_\Gamma \conj{\vv}\cdot \LL(\vu)
      \\
      \int_\Gamma \vu\cdot \LL(\conj{\vu}) &= -\norm{\vgrads{\vu}} \le 0
      \label{eq:hodge:negatif}
    \end{align}
  \end{prop}

  On rappelle que l'on veut trouver des conditions permettant de garantir \eqref{eq:unicite:form_var:cgu} soit \(\Re(X)\ge0\) où \(X = \int_\Gamma \vJ \cdot \conj{\vE_t}\).

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \subsection{CSU de la CI0}
    Considérons la condition d’impédance de Leontovich, la \hyperlink{ci0}{CI0} caractérisé par
    \begin{align}
      \label{eq:unicite:ci0}
      \vE_t = a_0 \vJ && \forall a_0 \in \CC
    \end{align}

    \begin{defn}
      \label{def:csu:ci0}
      On définit le sous-espace fermé de \(\CC\)
      \begin{equation*}
        \CSU{CI0} = \lbrace a_0 \in \CC; \Re(a_0) \ge 0 \rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une CSU pour la CI0]
      \label{prop:csu:ci0}
      Il suffit que
      \begin{equation*}
        a_0 \in \CSU{CI0}
      \end{equation*}
      pour que \(\Re(X)\ge 0\), ce qui entraîne l'unicité.
    \end{prop}
    \begin{proof}
      On a \( X = \conj{a_0}\norm{\vJ}^2\) donc \(\Re(X) = \Re(a_0)\norm{\vJ}^2 \)
    \end{proof}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \subsection{CSU de la CI01}
    Considérons la condition d’impédance \hyperlink{ci01}{CI01}:
    \begin{align}
      \label{eq:unicite:ci01}
      \vE_t = (a_0\oI + a_1 \LL)\vJ && \forall (a_0, a_1) \in \CC^2
    \end{align}

    \begin{defn}
      \label{def:csu:ci01}
      On définit le sous-espace fermé de \(\CC^2\)
      \begin{equation*}
        \CSU{CI01} = \left\lbrace (a_0,a_1) \in \CC^2; \begin{matrix}
        \Re\left(a_0\right) \ge 0
        \\
        \Re\left(a_1\right) \le 0
        \end{matrix}
        \right\rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une CSU pour la CI01]
      \label{prop:csu:ci01}
      Il suffit que
      \begin{equation*}
        (a_0,a_1) \in \CSU{CI01}
      \end{equation*}
      pour que \(\Re(X)\ge 0\), ce qui entraîne l'unicité.
    \end{prop}
    \begin{proof}
      On a
      \begin{align*}
        X & = \conj{a_0} \norm{\vJ} ^2 - \conj{a_1} \norm{\vgrads{\vJ}}^2
        \intertext{donc}
        \Re(X) & = \Re{(a_0)} \norm{\vJ} ^2 - \Re{(a_1)}\norm{\vgrads{\vJ}}^2
      \end{align*}
      Si on suppose \((a_0,a_1) \in \CSU{CI01}\), tous les termes sont positifs.
    \end{proof}

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \subsection{CSU de la CI1}

    Considérons la condition d’impédance \hyperlink{ci1}{CI1}:
    \begin{align}
    \label{eq:unicite:ci1}
      (\oI + b \LL) \vE_t = (a_0\oI + a_1 \LL) \vJ && \forall (a_0, a_1,b) \in \CC^3
    \end{align}

    Pour cette CIOE, nous démontrons qu'il existe plusieurs CSU.

    %\subsubsection{CSU de \cite{stupfel_sufficient_2011}}

    On définit 
    \begin{equation}
      \label{eq:unicite:delta}
      \begin{matrix}
        \Delta: & \CC^3 &\rightarrow& \CC
        \\
        & (a_0,a_1,b) & \mapsto & a_1 - a_0\conj{b}
      \end{matrix}
    \end{equation}
    Par abus de notation, on omet les variables \((a_0,a_1,b)\)
    \begin{equation}
       \Delta(a_0,a_1,b) \equiv \Delta
    \end{equation}

    On rappelle la CSU montrée dans \cite{stupfel_sufficient_2011}.

    \begin{defn}
      \label{def:csu:ci1-1}

      On définit le sous-espace ouvert de \(\CC^3\)
      \begin{equation*}
        \CSU[1]{CI1} = \left\lbrace 
        \begin{matrix}
        (a_0,a_1,b) \in \CC^3
        \\
        \Re(\Delta) = 0
        \\
        \Im(\Delta) \not = 0
        \\
        \Im(\Delta)\Im(b) \ge 0
        \\
        \Im(\Delta )\Im(a_1\conj{a_0})\ge 0
        \end{matrix}
        \right\rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une première CSU pour la CI1]
      \label{prop:csu:ci1-1}
      Il suffit que
      \begin{equation*}
        (a_0,a_1,b) \in \CSU[1]{CI1}
      \end{equation*}
      pour que \(\Re(X)\ge 0\), ce qui entraîne l'unicité.
    \end{prop}

    \begin{proof}
      On utilise l'identité \((a_1-a_0\conj{b})\oI = (a_1(\oI +\conj{b}\LL) - \conj{b}(a_0\oI + a_1\LL))\):
      \begin{align*}
        (a_1-a_0\conj{b})X &= \int_\Gamma \left(a_1(\oI +\conj{b}\LL) \vJ\right)\cdot\conj{\vE_t} - \left(\conj{b}(a_0\oI + a_1 \LL)\vJ\right)\cdot\conj{\vE_t}
        \intertext{Comme l'opérateur \(\LL\) est symétrique}
        (a_1-a_0\conj{b})X &= \int_\Gamma \left(a_1(\oI +\conj{b}\LL) \conj{\vE_t}\right)\cdot\vJ - \int_\Gamma \left(\conj{b}(a_0\oI + a_1 \LL)\vJ\right)\cdot\conj{\vE_t}
        \intertext{Par définition de la CI1}
        (a_1-a_0\conj{b})X &= \int_\Gamma \left(a_1(\conj{a_0}+\conj{a_1}\LL) \conj{\vJ}\right)\cdot\vJ - \int_\Gamma \left(\conj{b}(\oI +b \LL)\vE_t\right)\cdot\conj{\vE_t} \\
        (a_1-a_0\conj{b})X &= a_1\conj{a_0} \norm{ \vJ }^2 - |a_1|^2 \norm{\vgrads{\vJ}}^2 - \conj{b} \norm{ \vE_t }^2 + |b|^2\norm{\vgrads{\vE_t}}^2
      \end{align*}

      % On pose 
      % \begin{align*}
      %   F &= -\int_\Gamma \vJ \LL \conj{\vJ} \ge 0
      %   \\
      %   G &= -\int_\Gamma \vE_t \LL \conj{\vE_t} \ge 0
      % \end{align*}

      Explicitons la partie imaginaire de \( (a_1-a_0\conj{b})X\),
      \begin{align*}
        % \Re(\Delta)\Re(X) - \Im(\Delta)\Im(X) &= \Re(a_1\conj{a_0}) \norm{\vJ}^2 - \Re(\conj{b})\norm{\vE_t}^2 -|a_1|^2 F + |b|^2 G \\
        \Im(\Delta)\Re(X) + \Re(\Delta)\Im(X) &= \Im(a_1\conj{a_0}) \norm{\vJ}^2 - \Im(\conj{b})\norm{\vE_t}^2
        \intertext{En supposant \(\Re(\Delta)= 0\) et \(\Im(\Delta) \not = 0\) nous pouvons conclure car}
        \Im(\Delta)^2\Re(X) &= \Im(\Delta)\Im(a_1\conj{a_0}) \norm{\vJ}^2 - \Im(\Delta)\Im(\conj{b})\norm{\vE_t}^2
      \end{align*}
      Dans le cas où \(\Im(\Delta)\not=0\), il suffit d'imposer que tous ces termes soient positifs pour que \(\Re(X)\) le soit.
    \end{proof}

    On remarque que
    \begin{align}
      \CSU[1]{CI1} &\subset \CSU{CI01}\times\CC
      \\
      \CSU[1]{CI1}\cap(\CC^2 \times \lbrace0\rbrace) &\subsetneq (\CSU{CI01}\times\lbrace0\rbrace)
      \intertext{C'est insatisfaisant, car pour des fonctions infiniment régulières, la CIOE CI1 avec \(b=0\) est équivalente à la CI01.
      Plus précisément, soit \(S = \lbrace (a_0,a_1) \in \CC^2; \Re(a_1)=0 \rbrace\), on a}
      \CSU[1]{CI1}\cap(\CC^2 \times \lbrace0\rbrace) &= ((\CSU{CI01}\cap S) \times\lbrace0\rbrace) 
    \end{align}

    \begin{lemme}
      Soit \(z\in \CC\) et \(a\) alors la forme bilinéaire
      \begin{equation*}
        a(\vect{u},\vect{v}) = \int_\Gamma(\oI + z\LL)\vect{u}\cdot\conj{\vect{v}}
      \end{equation*}
      Si \(z\in \CC\backslash \RR_+^*\) alors \(a\) est coercive.
    \end{lemme}
    \begin{proof}
      \begin{align*}
        |a(\vect{u},\vect{u})|^2 &= \left(\norm{\vu}^2-\Re(z)\norm{\vgrads{\vu}}^2\right)^2 + \left(\Im(z)\norm{\vgrads{\vu}}^2\right)^2
        \\
        &= \begin{bmatrix}
          \norm{\vu}^2
          &
          \norm{\vgrads{\vu}}^2
        \end{bmatrix}
        \begin{bmatrix}
          1 & - \Re(z)
          \\
          -\Re(z) & |z|^2
        \end{bmatrix}
        \begin{bmatrix}
          \norm{\vu}^2
          \\
          \norm{\vgrads{\vu}}^2
        \end{bmatrix}
        \\
      \end{align*}
      Or la matrice n'est inversible que si \(\Im(z)^2\not=0\). Dans ce cas, on a la coercivité.

      Si \(\Im(z)=0\) alors
      \begin{align*}
        a(\vect{u},\vect{u}) &= \norm{\vu}^2-\Re(z)\norm{\vgrads{\vu}}^2
        \\
        &\ge \min(1,-\Re(z))\left(\norm{\vu}^2+\norm{\vgrads{\vu}}^2\right)
      \end{align*}
      Il suffit que \(-\Re(z) \ge 0 \) pour avoir la coercivité
    \end{proof}

    \begin{defn}
      \label{def:csu:ci1-2}

      On définit le sous-espace fermé de \(\CC^3\)
      \begin{equation*}
        \CSU[2]{CI1} = \left\lbrace 
        \begin{matrix}
        (a_0,a_1,b) \in \CC^3
        \\
        \Re(b) \le 0
        \\
        \Re\left(a_0\right) \ge 0
        \\
        \Re\left(b\conj{a_0}+\conj{a_1}\right) \le 0
        \\
        \Re\left(b\conj{a_1}\right) \ge 0
        \end{matrix}
        \right\rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une deuxième CSU pour la CI1]
      \label{prop:csu:ci1-2}
      Il suffit que
      \begin{equation*}
        (a_0,a_1,b) \in \CSU[2]{CI1}
      \end{equation*}
      pour que \(\Re(X)\ge 0\), ce qui entraîne l'unicité.
    \end{prop}

    \begin{proof}
      On suppose \(\Re(b)\le 0\) donc l'opérateur \(\oI + b\LL\) est bijectif. Il existe \(\vect{D}\) tel que
      \begin{align*}
        \vJ &= (\oI + b \LL)\vect{D}
      \end{align*}
      Donc 
      \begin{align*}
        (\oI + b \LL)\vE_t &= (a_0\oI + a_1\LL)\vJ
        \\
        (\oI + b \LL)\vE_t &= (a_0\oI + a_1\LL)(\oI + b \LL)\vect{D}
        \\
        0 &= (\oI + b \LL)(\vE_t -  (a_0\oI + a_1\LL)\vect{D})
        \intertext{L'opérateur est injectif donc}
        \vE_t &= (a_0\oI + a_1\LL)\vect{D}
        \\
        \int_\Gamma \vJ \cdot \conj{\vE_t} &= \int_\Gamma \vJ \cdot (\conj{a_0}\oI + \conj{a_1}\LL)\conj{\vect{D}}
        \\
        X &= \int_\Gamma (\oI + b \LL)\vect{D} \cdot (\conj{a_0}\oI + \conj{a_1}\LL)\conj{\vect{D}}
        \\
        X &= \conj{a_0}\norm{\vect{D}}^2 - (b\conj{a_0}+\conj{a_1})\norm{\vgrads{\vect{D}}}^2 + b\conj{a_1} \norm{\LL\vect{D}}^2
      \end{align*}
    \end{proof}

    On remarque que
    \begin{align}
      \CSU[2]{CI1} & \subset \CSU{CI01}\times\lbrace0\rbrace
      \\
      \CSU[2]{CI1}\cap(\CC^2 \times \lbrace0\rbrace) &= (\CSU{CI01}\times\lbrace0\rbrace)
    \end{align}

    Pour des fonctions infiniment régulières, la CIOE CI1 avec \(b=0\) est équivalente à la CI01 et la \CSU[2]{CI1} est donc meilleure que la  \CSU[1]{CI1}.