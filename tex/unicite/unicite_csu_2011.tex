\section[Des CSU pour les CIOE de Stupfel et Poget 2011]{Des conditions suffisantes pour les CIOE de \cite{stupfel_sufficient_2011}}

  Nous définissons les \glspl{acr-cioe} comme une condition limite liant \(\vE_t\) et \(\vn\pvect\vH\) sur \(\Gamma\). L'existence des CIOE est en dehors du cadre de cette thèse, nous ne ferons donc qu'utiliser des CIOE existantes.

  Grâce à ces CIOE, allons établir des conditions suffisantes qui impliquent la \gls{acr-cgu} \eqref{eq:unicite:form_var:cgu}. Par leur nature suffisante, il n'y pas un unique jeu de CSU pour une CIOE donnée. Une difficulté est d'être capable de juger si ce jeu est satisfaisant, et si ce n'est pas le cas, être capable de proposer un autre jeu.

  Les CIOE de \cite{stupfel_sufficient_2011} font intervenir l'opérateur de Hodge \(\mathcal{L}\), commençons par rappeler son expression et quelques propriétés.

  Soit les opérateurs différentiels surfaciques (voir annexe \ref{sec:annexe:div_grad_rot})
  \begin{align*}
      \vgrads{f}(\vx) &= \vgrad{f}(\vx) - \vn(\vx) (\vn(\vx) \cdot \vgrad{f}(\vx))
      \\
      \vdivs{\vu} &= \vdiv\left(\vu(\vx) - \vn(\vx) (\vn(\vx) \cdot \vu(\vx)\right)
      \\
      \vrots{\vu}(\vx) &= \vn(\vx)\left(\vn(\vx) \cdot \vrot{\vu}(\vx)\right)
  \end{align*}


  Enfin par abus de notations, nous omettrons tous les dépendances en \(\vx\) dans les intégrales \(\int_\Gamma f(\vx)\vE(\vx)\dd{\Gamma(\vx)}\equiv \int_\Gamma f\vE\).
  \begin{defn}
    \label{def:operator:L}
    % Pour tout \(\vu \in (\mathcal{C}^\infty(\Gamma))^2\)
    \begin{equation*}
        \fonction{\LL}{(\mathcal{C}^\infty(\Gamma))^3}{(\mathcal{C}^\infty(\Gamma))^3}%
          {\vu}{\vgrads{\vdivs \vu} - \vrots{\vrots \vu}}
    \end{equation*}
  \end{defn}

  \begin{prop}
    \label{eq:hodge:negatif}
    L’opérateur hermitien \(\LL\) est symétrique négatif.
  \end{prop}

  \begin{proof}
    Pour tous \(\vu,\vv \in (\mathcal C^\infty(\Gamma))^3\)
    \begin{align*}
      \int_\Gamma \vu\cdot \LL(\conj{\vv}) &= \int_\Gamma \conj{\vv}\cdot \LL(\vu)
      \\
      \int_\Gamma \vu\cdot \LL(\conj{\vu}) &= -\norm{\vdivs{\vu}}^2 - \norm{\vrots\vu}^2 \le 0
    \end{align*}
  \end{proof}

  \begin{prop}
    \label{prop:unicite:injectif:operateur:L}
    Soit \(\vu \in V=(\mathcal C^\infty(\Gamma))^3, a_0 \in \CC, a_1 \in \CC\).
    
    Soit \(\mathcal{P}\) l'opérateur tel que \(\mathcal{P}\vu = (a_0\oI + a_1 \LL)\vu\).

    Si \(\Re(a_0)\ge 0\) et \(\Re(a_1)\le 0\) alors l'opérateur \(\mathcal{P}\) est injectif sur \(V\).
  \end{prop}
  \begin{proof}
    Soit \(\vu \in \Ker{\mathcal{P}}\). Donc \(\mathcal{P}\vu  = 0\) ce qui implique,
    \begin{align*}
      \int_\Gamma \mathcal{P}\vu\cdot\conj{\vu}  &= 0
      \\
      & = \int_\Gamma (a_0\oI + a_1 \LL)\vu\cdot\conj{\vu}
      \\
      & = a_0 \norm{{\vu}}^2 - a_1 \left(\norm{\vdivs{\vu}}^2 + \norm{\vrots{\vu}}^2\right)
      \intertext{Donc}
      \Re\left(\int_\Gamma \mathcal{P}\vu\cdot\conj{\vu}\right) &= \Re(a_0) \norm{{\vu}}^2 - \Re(a_1) \left(\norm{\vdivs{\vu}}^2 + \norm{\vrots{\vu}}^2\right)
    \end{align*}
    Or \(\Re(a_0)\ge 0\) et \(\Re(a_1)\le 0\), donc tous les termes de l'expression précédente sont nuls donc \(\norm{\vu}=0\) donc \(\vu=0\).
    Donc l'opérateur \(\mathcal{P}\) est injectif.
  \end{proof}
  
  \begin{prop}
    \label{prop:unicite:inversible:operateur:L}
    Soit \(\vu \in V=\Sobolev[div]{(\Gamma)}\cap\Sobolev[rot]{(\Gamma)}\).
    
    Soit \(\mathcal{P}\) l'opérateur tel que \(\mathcal{P}\vu = (a_0\oI + a_1 \LL)\vu\).

    Si \(\Re(a_0)\ge 0\) et \(\Re(a_1)\le 0\) alors l'opérateur \(\mathcal{P}\) est bijectif sur \(V\).
  \end{prop}
  \begin{proof}
    D'après l'alternative de Fredholm (voir \cite[Théorème~VI.6, p.~92]{brezis_analyse_1996}), si l'opérateur \(\LL\) est compact, alors \(\mathcal{P}\) est soit non-injectif soit bijectif. D'après la proposition \ref{prop:unicite:injectif:operateur:L}, comme \(\Re(a_0)\ge 0\) et \(\Re(a_1)\le 0\) alors il est injectif.
    Montrons que \(\LL\) est compact.
  \end{proof}


  On rappelle que l'on veut trouver des conditions permettant de garantir \eqref{eq:unicite:form_var:cgu} soit \(\Re(X)\ge0\) où \(X = \int_\Gamma \vJ \cdot \conj{\vE_t}\) sachant que \gls{phy-J} est la trace tangentielle sur \(\Gamma\) de l’excitation magnétique (\(\vJ = \vn \pvect \vH\)).

  Ces conditions garantissent que \((\vE,\vH) = (0,0)\) est l'unique solution de 
  \begin{equation}
    \label{eq:unicite:probleme_sans_ci}
    \begin{aligned}
      \left\lbrace
      \begin{aligned}
        \vrot{\vE} + ik_0\vH &= 0
        \\
        \vrot{\vH} - ik_0\vE &= 0
      \end{aligned}
      \right. && \text{dans \(\OO^c_R\)},
      \\
      \Tr(\vE_t) = - \vn_{S_R} \pvect \vH && \text{sur \(S_R\),}
      \\
      \text{une condition limite définit ci-après }  && \text{sur \(\Gamma\).}
    \end{aligned}
  \end{equation}

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \subsection{CSU de la CI0}
    Considérons la condition d’impédance de Leontovich, la \hyperlink{ci0}{CI0} caractérisée par
    \begin{align}
      \label{eq:unicite:ci0}
      \vE_t = a_0 \vJ &&  a_0 \in \CC
    \end{align}

    \begin{defn}
      \label{def:csu:ci0}
      On définit le sous-espace fermé de \(\CC\)
      \begin{equation*}
        \CSU{CI0} = \lbrace a_0 \in \CC, \Re(a_0) \ge 0 \rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une CSU pour la CI0]
      \label{prop:csu:ci0}
      Si
      \begin{equation*}
        a_0 \in \CSU{CI0}
      \end{equation*}
      alors le problème \eqref{eq:unicite:probleme_sans_ci} avec la CI0 a une unique solution.
    \end{prop}
    \begin{proof}
      Cela découle de \( X = \conj{a_0}\norm{\vJ}^2\) donc \(\Re(X) = \Re(a_0)\norm{\vJ}^2 \).
    \end{proof}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \subsection{CSU de la CI01}
    Considérons la condition d’impédance \hyperlink{ci01}{CI01}:
    \begin{align}
      \label{eq:unicite:ci01}
      \vE_t = (a_0\oI + a_1 \LL)\vJ && \forall (a_0, a_1) \in \CC^2
    \end{align}

    \begin{defn}
      \label{def:csu:ci01}
      On définit le sous-espace fermé de \(\CC^2\)
      \begin{equation*}
        \CSU{CI01} = \left\lbrace (a_0,a_1) \in \CC^2,
        \begin{matrix}
        \Re\left(a_0\right) \ge 0
        \\
        \Re\left(a_1\right) \le 0
        \end{matrix}
        \right\rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une CSU pour la CI01]
      \label{prop:csu:ci01}
      Si
      \begin{equation*}
        (a_0,a_1) \in \CSU{CI01}
      \end{equation*}
      alors le problème \eqref{eq:unicite:probleme_sans_ci} avec la CI01 a une unique solution.
    \end{prop}
    \begin{proof}
      On a
      \begin{align*}
        X & = \conj{a_0} \norm{\vJ} ^2 - \conj{a_1} \left(\norm{\vdivs{\vJ}}^2 + \norm{\vrots{\vJ}}^2\right)
        \intertext{donc}
        \Re(X) & = \Re{(a_0)} \norm{\vJ} ^2 - \Re{(a_1)}\left(\norm{\vdivs{\vJ}}^2 + \norm{\vrots{\vJ}}^2\right)
      \end{align*}
      Si l’on suppose \((a_0,a_1) \in \CSU{CI01}\), tous les termes sont positifs donc \(\Re(X)\ge 0\).
    \end{proof}

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \subsection{CSU de la CI1}

    Considérons la condition d’impédance \hyperlink{ci1}{CI1}:
    \begin{align}
    \label{eq:unicite:ci1}
      (\oI + b \LL) \vE_t = (a_0\oI + a_1 \LL) \vJ && \forall (a_0, a_1,b) \in \CC^3
    \end{align}

    Pour cette CIOE, nous observons qu'il y plusieurs sous-espaces différents, inclus dans \(\CC^3\) qui conduisent à l'unicité de la solution du problème.

    %\subsubsection{CSU de \cite{stupfel_sufficient_2011}}

    On définit 
    \begin{equation}
      \label{eq:unicite:delta}
      \begin{matrix}
        \Delta: & \CC^3 &\rightarrow& \CC
        \\
        & (a_0,a_1,b) & \mapsto & a_1 - a_0\conj{b}.
      \end{matrix}
    \end{equation}
    Par abus de notation, on omet les variables \((a_0,a_1,b)\)
    \begin{equation}
       \Delta(a_0,a_1,b) \equiv \Delta.
    \end{equation}

    On rappelle la CSU énoncée dans \cite{stupfel_sufficient_2011}.

    \begin{defn}
      \label{def:csu:ci1-1}

      On définit le sous-espace ouvert de \(\CC^3\)
      \begin{equation*}
        \CSU[1]{CI1} = \left\lbrace 
        (a_0,a_1,b) \in \CC^3,
        \begin{matrix}
        \Re(\Delta) = 0
        \\
        \Im(\Delta) \not = 0
        \\
        \Im(\Delta)\Im(b) \ge 0
        \\
        \Im(\Delta )\Im(a_1\conj{a_0})\ge 0
        \end{matrix}
        \right\rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une première CSU pour la CI1]
      \label{prop:csu:ci1-1}
      On a 
      \begin{equation*}
        (a_0,a_1,b) \in \CSU[1]{CI1} \Rightarrow \Re(X)\ge 0. 
      \end{equation*}
      C'est à dire \((a_0,a_1,b) \in \CSU[1]{CI1}\) entraîne l'unicité de la solution du problème \eqref{eq:unicite:probleme_sans_ci} avec la CI1.
    \end{prop}

    \begin{proof}
      On utilise l'identité \(\Delta\oI = (a_1(\oI +\conj{b}\LL) - \conj{b}(a_0\oI + a_1\LL))\):
      \begin{align*}
        \Delta X &= \int_\Gamma \left(a_1(\oI +\conj{b}\LL) \vJ\right)\cdot\conj{\vE_t} - \left(\conj{b}(a_0\oI + a_1 \LL)\vJ\right)\cdot\conj{\vE_t}
        \intertext{Comme l'opérateur \(\LL\) est symétrique}
        \Delta X &= \int_\Gamma \left(a_1(\oI +\conj{b}\LL) \conj{\vE_t}\right)\cdot\vJ - \int_\Gamma \left(\conj{b}(a_0\oI + a_1 \LL)\vJ\right)\cdot\conj{\vE_t}
        \intertext{En utilisant la CI1}
        \Delta X &= \int_\Gamma \left(a_1(\conj{a_0}+\conj{a_1}\LL) \conj{\vJ}\right)\cdot\vJ - \int_\Gamma \left(\conj{b}(\oI +b \LL)\vE_t\right)\cdot\conj{\vE_t} \\
        \Delta X &= a_1\conj{a_0} \norm{ \vJ }^2 - |a_1|^2 \left(\norm{\vdivs{\vJ}}^2 + \norm{\vrots{\vJ}}^2\right) - \conj{b} \norm{ \vE_t }^2 + |b|^2\left(\norm{\vdivs{\vE_t}}^2 + \norm{\vrots{\vE_t}}^2\right)
      \end{align*}

      % On pose 
      % \begin{align*}
      %   F &= -\int_\Gamma \vJ \LL \conj{\vJ} \ge 0
      %   \\
      %   G &= -\int_\Gamma \vE_t \LL \conj{\vE_t} \ge 0
      % \end{align*}

      La partie imaginaire de \(\Delta X\) est
      \begin{align*}
        % \Re(\Delta)\Re(X) - \Im(\Delta)\Im(X) &= \Re(a_1\conj{a_0}) \norm{\vJ}^2 - \Re(\conj{b})\norm{\vE_t}^2 -|a_1|^2 F + |b|^2 G \\
        \Im(\Delta X)&= \Im(a_1\conj{a_0}) \norm{\vJ}^2 - \Im(\conj{b})\norm{\vE_t}^2
        \intertext{\(\Im(\Delta X) = \Im(\Delta)\Re(X)\) ce qui entraine si \((a_0,a_1,b)\in\CSU[1]{CI1}\) alors \(\Re(\Delta)=0, \Im(\Delta)\not=0\) d'où}
        \Im(\Delta)^2\Re(X) &= \Im(\Delta)\Im(a_1\conj{a_0}) \norm{\vJ}^2 + \Im(\Delta)\Im({b})\norm{\vE_t}^2
      \end{align*}
      Les deux autres conditions de la CSU imposent que les termes du membre de droite sont positifs donc \(\Re(X)\ge0\).
    \end{proof}

    On remarque que
    \begin{align}
      \CSU[1]{CI1} &\subset \CSU{CI01}\times\CC
      \\
      \CSU[1]{CI1}\cap(\CC^2 \times \lbrace0\rbrace) &\subsetneq (\CSU{CI01}\times\lbrace0\rbrace)
      \intertext{Comme La CIOE CI1 avec \(b=0\) est équivalente à la CI01, cela veut dire que cette CSU n'est pas idéale. 
      Plus précisément, soit \(S = \lbrace (a_0,a_1) \in \CC^2; \Re(a_1)=0 \rbrace\), on a}
      \CSU[1]{CI1}\cap(\CC^2 \times \lbrace0\rbrace) &= ((\CSU{CI01}\cap S) \times\lbrace0\rbrace) 
    \end{align}

    % \begin{lemme}
    % \label{lem:coercivite:operateur-l}
    %   Soit \(z\in \CC\), \(\vu,\vv \in \Sobolev[1]{(\Gamma)}\) et \(a\) la forme bilinéaire
    %   \begin{equation*}
    %     a(\vect{u},\vect{v}) = \int_\Gamma(\oI + z\LL)\vect{u}\cdot\conj{\vect{v}}.
    %   \end{equation*}
    %   Si \(z\in \CC\backslash \RR_+^*\) alors \(a\) est coercive sur \(\Sobolev[1]{(\Gamma)}\).
    % \end{lemme}
    % \begin{proof}
    %   On cherche à montrer que \(\exists \delta \in \RR^+, \forall \vu \in \Sobolev[1]{(\Gamma)}, |a(\vu,\vu)|^2\ge \delta\left(\norm{\vu}^2+\norm{\vdivs{\vu}}^2+\norm{\vrots{\vu}}^2\right)^2\).
    %   \begin{align*}
    %     |a(\vect{u},\vect{u})|^2 &= \left(\norm{\vu}^2-\Re(z)\left(\norm{\vdivs{\vu}}^2+\norm{\vrots{\vu}}^2\right)\right)^2 + \left(\Im(z)\left(\norm{\vdivs{\vu}}^2+\norm{\vrots{\vu}}^2\right)\right)^2
    %     \\
    %     &= \begin{bmatrix}
    %       \norm{\vu}^2
    %       &
    %       \norm{\vdivs{\vu}}^2+\norm{\vrots{\vu}}^2
    %     \end{bmatrix}
    %     \begin{bmatrix}
    %       1 & - \Re(z)
    %       \\
    %       -\Re(z) & |z|^2
    %     \end{bmatrix}
    %     \begin{bmatrix}
    %       \norm{\vu}^2
    %       \\
    %       \norm{\vdivs{\vu}}^2+\norm{\vrots{\vu}}^2
    %     \end{bmatrix}
    %     \\
    %   \end{align*}
    %   Cette matrice est positive. Mais elle n'est définie que si \((\Im(z))^2\not=0\). Dans ce cas, on a la coercivité \(\Sobolev[1]{(\Gamma})\).

    %   Si \(\Im(z)=0\) alors
    %   \begin{align*}
    %     a(\vect{u},\vect{u}) &= \norm{\vu}^2-\Re(z)\left(\norm{\vdivs{\vu}}^2+\norm{\vrots{\vu}}^2\right)
    %     \\
    %     &\ge \min(1,-\Re(z))\left(\norm{\vu}^2+\norm{\vdivs{\vu}}^2+\norm{\vrots{\vu}}^2\right).
    %   \end{align*}
    %   Il suffit que \(\Re(z) < 0 \) pour avoir la coercivité
    % \end{proof}

    \begin{defn}
      \label{def:csu:ci1-2}

      On définit le sous-espace fermé de \(\CC^3\)
      \begin{equation*}
        \CSU[2]{CI1} = \left\lbrace
        (a_0,a_1,b) \in \CC^3,
        \begin{matrix}
        \Re(b) \le 0
        \\
        \Re\left(a_0\right) \ge 0
        \\
        \Re\left(b\conj{a_0}+\conj{a_1}\right) \le 0
        \\
        \Re\left(b\conj{a_1}\right) \ge 0
        \end{matrix}
        \right\rbrace
      \end{equation*}
    \end{defn}

    \begin{prop}[Une deuxième CSU pour la CI1]
      \label{prop:csu:ci1-2}
      On a 
      \begin{equation*}
        (a_0,a_1,b) \in \CSU[2]{CI1} \Rightarrow \Re(X)\ge 0. 
      \end{equation*}
      C'est à dire \((a_0,a_1,b) \in \CSU[2]{CI1}\) entraîne l'unicité de la solution du problème \eqref{eq:unicite:probleme_sans_ci} avec la CI1.
    \end{prop}

    \begin{proof}
      Comme on suppose \(\Re(b)\le 0\) donc l'opérateur \(\oI + b\LL\) est injectif d'après la propriété \ref{prop:unicite:injectif:operateur:L}.

      Il existe donc \(\vect{D}\) tel que
      \begin{align*}
        (\oI + b \LL)^{-1}\vJ &= \vect{D}.
      \end{align*}
      Donc 
      \begin{align*}
        (\oI + b \LL)\vE_t &= (a_0\oI + a_1\LL)\vJ,
        \\
        (\oI + b \LL)\vE_t &= (a_0\oI + a_1\LL)(\oI + b \LL)\vect{D},
        \\
        0 &= (\oI + b \LL)(\vE_t -  (a_0\oI + a_1\LL)\vect{D}).
        \intertext{L'opérateur \(\oI + b \LL\) est injectif donc}
        \vE_t &= (a_0\oI + a_1\LL)\vect{D},
        \\
        \int_\Gamma \vJ \cdot \conj{\vE_t} &= \int_\Gamma \vJ \cdot (\conj{a_0}\oI + \conj{a_1}\LL)\conj{\vect{D}}
        \intertext{On rappelle \(\vJ = (\oI + b \LL)\vect{D}.\)},
        \\
        X &= \int_\Gamma (\oI + b \LL)\vect{D} \cdot (\conj{a_0}\oI + \conj{a_1}\LL)\conj{\vect{D}}.
        \\
        \intertext{Or on sait d'après la définition de l'opérateur \(\LL\) }
        X &= \conj{a_0}\norm{\vect{D}}^2 - (b\conj{a_0}+\conj{a_1})\left(\norm{\vdivs{\vect{D}}}^2+\norm{\vrots{\vect{D}}}^2\right) + b\conj{a_1} \norm{\LL\vect{D}}^2.
      \end{align*}
    \end{proof}

    On remarque que
    \begin{align}
      \CSU[2]{CI1} & \subset \CSU{CI01}\times\lbrace0\rbrace
      \\
      \CSU[2]{CI1}\cap(\CC^2 \times \lbrace0\rbrace) &= (\CSU{CI01}\times\lbrace0\rbrace)
    \end{align}

    Pour des fonctions infiniment régulières, la CIOE CI1 avec \(b=0\) est équivalente à la CI01 et la \CSU[2]{CI1} est donc meilleure que la  \CSU[1]{CI1}.
